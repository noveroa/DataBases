{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now just using DF directly\n",
    "## no longer need to parse separately into lists etc.  all done internally\n",
    "## TO Do the dump load and initialize the DB, need to make sure correct order pf tables is loaded first those with no dependencies and then increasingly so.\n",
    "## now only erroring on original 3 .txt noted by Ian Gorton in original commnication\n",
    "- - 1. Conf\n",
    "- - 2. Pub , Keys, Authors, Affiliations (use sets to create unique ones but may change to all .unique)\n",
    "- - 3. Composites (Many to Many)\n",
    "- - 4. Paper/abstracts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1061, 7)\n",
      "(1061, 7)\n"
     ]
    }
   ],
   "source": [
    "import sqlcommands as cmd\n",
    "cmd = reload(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aileennovero1/anaconda/lib/python2.7/site-packages/pandas/core/generic.py:1160: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author affiliation</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Conf</th>\n",
       "      <th>Title</th>\n",
       "      <th>terms</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Enterprise Architecture  EA  has undergone man...</td>\n",
       "      <td>International Graduate School of Dynamic Intel...</td>\n",
       "      <td>['Assmann, Martin', ' ,', '', ' Engels, Gregor...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Transition to service oriented enterprise arch...</td>\n",
       "      <td>['Architecture', 'Information services', 'Web ...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>In domains, where great variability of require...</td>\n",
       "      <td>Kaunas University of Technology, Studentu 50, ...</td>\n",
       "      <td>['Damaevicius, Robertas', '', '', '', ' tuikys...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Domain ontology based generative component des...</td>\n",
       "      <td>['Digital signal processing', 'Integrated circ...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Software architecture can be represented as a ...</td>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>['Lee, Larix', '', '', 'Kruchten, Philippe']</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Visualizing software architectural design deci...</td>\n",
       "      <td>['Design', 'Software architecture', 'Software ...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>In this paper, we propose the application of c...</td>\n",
       "      <td>Federal University of Rio Grande do Norte  UFR...</td>\n",
       "      <td>['Batista, Thais', '', '', 'Gomes, Ant', ' nio...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>On the interplay of aspects and dynamic reconf...</td>\n",
       "      <td>['Blending', 'Dynamic models', 'Software desig...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Empirical software engineering focuses on the ...</td>\n",
       "      <td>DISP, Univ  of Rome, Rome, Italy</td>\n",
       "      <td>['Falessi, D', '', '', ' Kruchten, P', ' Canto...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Issues in applying empirical software engineer...</td>\n",
       "      <td>['software architecture', 'software quality', ...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Software architecture description languages al...</td>\n",
       "      <td>LSTS   ENIT, Tunis, Tunisia</td>\n",
       "      <td>['Jerad, C', '', '', ' Barkaoui, K', ' Grissa ...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Hierarchical verification in Maude of LfP soft...</td>\n",
       "      <td>['formal verification', 'rewriting systems', '...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>When an application must evolve to cope with n...</td>\n",
       "      <td>INRIA, Univ  des Sci  et Technol  de Lille, Vi...</td>\n",
       "      <td>['Waignier, G', '', '', ' Le Meur, A', 'F', ''...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>FIESTA  a generic framework for integrating ne...</td>\n",
       "      <td>['formal specification', 'software architectur...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ageless software evolves, to meet new requirem...</td>\n",
       "      <td>Sch  of Comput  Sci , Univ  of Adelaide, Adela...</td>\n",
       "      <td>['Falkner, K', '', '', ' Balasubramaniam, D', ...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Informed evolution</td>\n",
       "      <td>['software architecture', 'software prototypin...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>The past 20 years has seen significant investm...</td>\n",
       "      <td>Software Group, IBM, Raleigh, NC, United States</td>\n",
       "      <td>['Brown, A W', '', '', ' McDermid, J A']</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>The art and science of software architecture</td>\n",
       "      <td>['safety-critical software', 'software archite...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Many issues must be taken into account in orde...</td>\n",
       "      <td>Comput  Syst  Dept , UCLM, Albacete, Spain</td>\n",
       "      <td>['Navarro, E', '', '', ' Letelier, P', ' Jaen,...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Supporting the automatic generation of proto a...</td>\n",
       "      <td>['software architecture', 'proto-architectures...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Abstract  \\\n",
       "50  Enterprise Architecture  EA  has undergone man...   \n",
       "51  In domains, where great variability of require...   \n",
       "52  Software architecture can be represented as a ...   \n",
       "53  In this paper, we propose the application of c...   \n",
       "54  Empirical software engineering focuses on the ...   \n",
       "55  Software architecture description languages al...   \n",
       "56  When an application must evolve to cope with n...   \n",
       "57  Ageless software evolves, to meet new requirem...   \n",
       "58  The past 20 years has seen significant investm...   \n",
       "59  Many issues must be taken into account in orde...   \n",
       "\n",
       "                                   Author affiliation  \\\n",
       "50  International Graduate School of Dynamic Intel...   \n",
       "51  Kaunas University of Technology, Studentu 50, ...   \n",
       "52                     University of British Columbia   \n",
       "53  Federal University of Rio Grande do Norte  UFR...   \n",
       "54                   DISP, Univ  of Rome, Rome, Italy   \n",
       "55                        LSTS   ENIT, Tunis, Tunisia   \n",
       "56  INRIA, Univ  des Sci  et Technol  de Lille, Vi...   \n",
       "57  Sch  of Comput  Sci , Univ  of Adelaide, Adela...   \n",
       "58    Software Group, IBM, Raleigh, NC, United States   \n",
       "59         Comput  Syst  Dept , UCLM, Albacete, Spain   \n",
       "\n",
       "                                              Authors  Conf  \\\n",
       "50  ['Assmann, Martin', ' ,', '', ' Engels, Gregor...  ECSA   \n",
       "51  ['Damaevicius, Robertas', '', '', '', ' tuikys...  ECSA   \n",
       "52       ['Lee, Larix', '', '', 'Kruchten, Philippe']  ECSA   \n",
       "53  ['Batista, Thais', '', '', 'Gomes, Ant', ' nio...  ECSA   \n",
       "54  ['Falessi, D', '', '', ' Kruchten, P', ' Canto...  ECSA   \n",
       "55  ['Jerad, C', '', '', ' Barkaoui, K', ' Grissa ...  ECSA   \n",
       "56  ['Waignier, G', '', '', ' Le Meur, A', 'F', ''...  ECSA   \n",
       "57  ['Falkner, K', '', '', ' Balasubramaniam, D', ...  ECSA   \n",
       "58           ['Brown, A W', '', '', ' McDermid, J A']  ECSA   \n",
       "59  ['Navarro, E', '', '', ' Letelier, P', ' Jaen,...  ECSA   \n",
       "\n",
       "                                                Title  \\\n",
       "50  Transition to service oriented enterprise arch...   \n",
       "51  Domain ontology based generative component des...   \n",
       "52  Visualizing software architectural design deci...   \n",
       "53  On the interplay of aspects and dynamic reconf...   \n",
       "54  Issues in applying empirical software engineer...   \n",
       "55  Hierarchical verification in Maude of LfP soft...   \n",
       "56  FIESTA  a generic framework for integrating ne...   \n",
       "57                                 Informed evolution   \n",
       "58       The art and science of software architecture   \n",
       "59  Supporting the automatic generation of proto a...   \n",
       "\n",
       "                                                terms  year  \n",
       "50  ['Architecture', 'Information services', 'Web ...  2008  \n",
       "51  ['Digital signal processing', 'Integrated circ...  2008  \n",
       "52  ['Design', 'Software architecture', 'Software ...  2008  \n",
       "53  ['Blending', 'Dynamic models', 'Software desig...  2008  \n",
       "54  ['software architecture', 'software quality', ...  2008  \n",
       "55  ['formal verification', 'rewriting systems', '...  2008  \n",
       "56  ['formal specification', 'software architectur...  2008  \n",
       "57  ['software architecture', 'software prototypin...  2008  \n",
       "58  ['safety-critical software', 'software archite...  2008  \n",
       "59  ['software architecture', 'proto-architectures...  2008  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cmd.createTOTALTable()\n",
    "df.iloc[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#don't need \n",
    "#df1 = cmd.getPatentDataFrame(hdffile='../DataBaseParsing/DFstore4.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DISP, Univ  of Rome, Rome, Italy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Author affiliation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Conf Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "confDF = cmd.createConfTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confID</th>\n",
       "      <th>confName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>QoSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WICSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confID confName\n",
       "0       1     ECSA\n",
       "1       2     QoSA\n",
       "2       3    WICSA"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create publications Table\n",
    "## Now can parse all the orginal .txt with exception of the same 3  Ian gorton noted were errant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "table dropped\n",
      "Created PUBLICATIONS table\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "pubDF = cmd.createPublicationsTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubID</th>\n",
       "      <th>year</th>\n",
       "      <th>confName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pubID  year confName\n",
       "0      1  2007     ECSA\n",
       "1      2  2008     ECSA\n",
       "2      3  2009     ECSA\n",
       "3      4  2010     ECSA\n",
       "4      5  2011     ECSA"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubDF.head()\n",
    "#pubDF.to_csv('Tables_v1/publications.csv', sheet_name = 'publications')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Keys Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are errors here and I have spent way to ong trying to figure if out.  \n",
    "## Somewhere the abstracts are being split into the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "           keyword\n",
      "0  Loose couplings\n",
      "1         Simulink\n",
      "2             FUML\n",
      "3    Bayesian nets\n",
      "4            NoSQL\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "keys = cmd.createKEYSTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5308\n",
      "5308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyID</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Loose couplings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Simulink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FUML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bayesian nets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NoSQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>New product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Agile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>directed graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Application-Specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Multiple levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Language design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Local decision-making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Software life cycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Sensing devices and transducers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Time measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Anecdotal evidences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>software performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Information services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Validation results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Traffic simulations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keyID                          keyword\n",
       "0       1                  Loose couplings\n",
       "1       2                         Simulink\n",
       "2       3                             FUML\n",
       "3       4                    Bayesian nets\n",
       "4       5                            NoSQL\n",
       "5       6                      New product\n",
       "6       7                            Agile\n",
       "7       8                   directed graph\n",
       "8       9             Application-Specific\n",
       "9      10                  Multiple levels\n",
       "10     11                  Language design\n",
       "11     12            Local decision-making\n",
       "12     13             Software life cycles\n",
       "13     14  Sensing devices and transducers\n",
       "14     15                 Time measurement\n",
       "15     16              Anecdotal evidences\n",
       "16     17             software performance\n",
       "17     18             Information services\n",
       "18     19               Validation results\n",
       "19     20              Traffic simulations"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(keys)\n",
    "print len(keys.keyword.unique())\n",
    "keys.iloc[50:75]\n",
    "keys.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors\n",
    "## I don't know how to parse them better!  Each text file seems to look at them differently and no idea what to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Author set created\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "authorsDF = cmd.createAUTHORSTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorID</th>\n",
       "      <th>authorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Von Massow  Robert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Smiley  Karen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Westermann  Dennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Porres  Ivan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dos Santos  Rodrigo Pereira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorID                   authorName\n",
       "0         1           Von Massow  Robert\n",
       "1         2                Smiley  Karen\n",
       "2         3           Westermann  Dennis\n",
       "3         4                 Porres  Ivan\n",
       "4         5  Dos Santos  Rodrigo Pereira"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(authorsDF.authorName.drop_duplicates())  #<<--- double check!  will keep one 'empty ' ' becuase of set)\n",
    "authorsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEFAULTDB = mydb\n",
    "def createAUTHORSTable(data_frame, \n",
    "                    db = DEFAULTDB, \n",
    "                    DFCol = 'Authors',\n",
    "                    table = 'AUTHORS' ,\n",
    "                    tableCol = ['authorName']\n",
    "                   ):\n",
    "    ''' Creating the AUTHORS Table with \n",
    "            authorID as AUTOINCREMENTED PRIMARY KEY, \n",
    "             : param data_frame : Pandas DataFrame from which to create the AUTHORS TABLE\n",
    "             : param db : str. Name of db. (ie. 'Abstracts.db')\n",
    "                 : default 'test.db'\n",
    "             : param DFCol : tuple of strings Column names of data_frame with groupby cols.\n",
    "                 : default = 'Authors'\n",
    "                 : alternatively : enter with already unique table.\n",
    "             : param table : str. Name of Table to create or insert.\n",
    "                 : default : AUTHORS\n",
    "             : param tableCols : tuple of str. Table keywords as tuple of strings\n",
    "                 : default  : ('authorName')\n",
    "             : **NEED TO CREATE COMPOSITE **\n",
    "         \n",
    "             : output : Pandas DataFrame as output for inspection\n",
    "             : output : sql table created with rows inserted.\n",
    "         '''\n",
    "    \n",
    "    def findAuthorsSet(data_frame, DFCol = DFCol):\n",
    "        ''' Parse the TOTALABSTRACTS table dataframe terms column.\n",
    "        Create a single set of all terms\n",
    "        \n",
    "        : param data_frame : a Pandas DataFrame (ie TOTALABSTRACTS table as DF)\n",
    "        : param DFCol : column name to be recast and set of terms found from\n",
    "        \n",
    "        : output : a master set of terms set as a list (no duplicates)\n",
    "        '''\n",
    "        import re\n",
    "        commaQuote = re.compile('[\\',]')\n",
    "        \n",
    "    \n",
    "        #recast - since made a string during the entry into the sqlite db.\n",
    "        authors = data_frame[DFCol].apply(lambda a: a.strip(\"[]'\"))\n",
    "        authors = authors.apply(lambda x: filter(lambda a: a != '',\n",
    "                                                  commaQuote.sub(' ', x).split('   ')))\n",
    "        \n",
    "        \n",
    "        #create single set and remove leading white space\n",
    "        authors = list(frozenset().union(*authors))\n",
    "        authors = [anew.strip(' ') for anew in authors]\n",
    "        #need to reset becuase of the white space\n",
    "        return list(set(authors))\n",
    "    with sqlite3.connect(db) as con:\n",
    "        print (\"Opened %s database successfully\" %db); \n",
    "        cur = con.cursor() \n",
    "        #drops the Authors table if it exist in db already\n",
    "        cur.execute(\"DROP TABLE IF EXISTS \" + table)\n",
    "        #and recreates it\n",
    "        cur.execute(\"CREATE TABLE \" + table + \"(\\\n",
    "        authorID INTEGER PRIMARY KEY AUTOINCREMENT, \\\n",
    "        authorName TEXT \\\n",
    "        )\") \n",
    "        authors = findAuthorsSet(data_frame)\n",
    "        print ('Author set created')\n",
    "        \n",
    "        #only take 1 -> becuase first is empty\n",
    "        authorsDF = pd.DataFrame(authors[1:], columns = tableCol)\n",
    "        \n",
    "        #insert into the table\n",
    "        authorsDF.to_sql(table, con, flavor='sqlite', \n",
    "                    schema=None, if_exists='append', \n",
    "                    index=False, index_label=None,\n",
    "                    chunksize=None, dtype=None)\n",
    "        print(\"Records created successfully\");\n",
    "        \n",
    "    sql = \"SELECT * FROM \" + table\n",
    "    dfAuthors = pd.read_sql_query(sql, con)\n",
    "        \n",
    "    #return table as Pandas DataFrame for inspection\n",
    "    return dfAuthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Author set created\n",
      "Records created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsDF = cmd.createAUTHORSTable(df)\n",
    "authorsDF.head()\n",
    "len(authorsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affiliation Table\n",
    "## simple no extra parsing do to differences between entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "affilDF= cmd.createAFFILIATIONTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affilID</th>\n",
       "      <th>affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DISP, Univ  of Rome, Rome, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LSTS   ENIT, Tunis, Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>INRIA, Univ  des Sci  et Technol  de Lille, Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sch  of Comput  Sci , Univ  of Adelaide, Adela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Software Group, IBM, Raleigh, NC, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   affilID                                        affiliation\n",
       "0        1                   DISP, Univ  of Rome, Rome, Italy\n",
       "1        2                        LSTS   ENIT, Tunis, Tunisia\n",
       "2        3  INRIA, Univ  des Sci  et Technol  de Lille, Vi...\n",
       "3        4  Sch  of Comput  Sci , Univ  of Adelaide, Adela...\n",
       "4        5    Software Group, IBM, Raleigh, NC, United States"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affilDF.head()\n",
    "#affilDF.to_csv('Tables_v1/affiliations.csv', sheet_name = 'affilations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PAPER TABLE\n",
    "## should this actually be made by first doing a join or something with the pub table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "table dropped\n",
      "Created PAPER table\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "paperDF= cmd.createPAPERTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"['Software design', 'Structural properties', 'Feature models', 'Product-lines', 'Research challenges', 'Software product line architecture', 'Software product lines', 'Software systems', 'Structural Design', 'Computer Programming', 'Materials Science']\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperDF.iloc[0].terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydb = 'Abstracts_DB2.db'\n",
    "#paperDF.to_csv('Tables_v1/paper.csv', sheet_name = 'paper')\n",
    "paperDFbyYrandConf = paperDF[['pubYear', 'confName', 'paperID']].groupby(['pubYear', 'confName'], axis = 0)\n",
    "#paperDFbyYrandConf.count().to_html()\n",
    "paperDFbyYrandConf.get_group((2007, 'ECSA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPapersConfYr(yr, conf):\n",
    "    with sqlite3.connect(mydb) as con:\n",
    "        sqlcmd = \"SELECT pubYear, confName, paperID, title, abstract FROM PAPER\"\n",
    "        PAPdf = pd.read_sql_query(sqlcmd, con)\n",
    "    \n",
    "        group = PAPdf.groupby(['pubYear', 'confName'], axis = 0)\n",
    "        subgrp = group.get_group((yr, conf))\n",
    "        \n",
    "        return subgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = getPapersConfYr(2004, 'WICSA')\n",
    "y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mytable = []\n",
    "for idx in y.index.get_values():\n",
    "    entry = {}\n",
    "    entry['paperID'] = y.loc[idx]['paperID']\n",
    "    entry['title'] = y.loc[idx]['title']\n",
    "    entry['abstract'] = y.loc[idx]['abstract']\n",
    "    mytable.append(entry)\n",
    "x = dict(data = mytable)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PAPERKEY COMPOSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sqlcommands.py:556: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  parsedPaper['NEWTERMS'] = parsedPaper[DFCol[-1]].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "pk = cmd.createPAPERKEYTable(paperDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Research challenges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Software product line architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Structural properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Software product lines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paperID                             keyword\n",
       "0        1                 Research challenges\n",
       "1        1  Software product line architecture\n",
       "2        1                   Materials Science\n",
       "3        1               Structural properties\n",
       "4        1              Software product lines"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperKey = pk.merge(paperDF[['paperID', 'title','confName', 'pubYear']], on = 'paperID')\n",
    "paperKey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPapersKWgroup(grouper):\n",
    "    with sqlite3.connect('Abstracts_DB.db') as con:\n",
    "        sqlcmd = \"SELECT paperID, title, confName, pubYear FROM PAPER \"\n",
    "        \n",
    "        paperdf = pd.read_sql_query(sqlcmd, con)\n",
    "        \n",
    "        sqlcmd2 = \"SELECT paperID, keyword FROM PAPERKEY \"\n",
    "        kwdf = pd.read_sql_query(sqlcmd2, con)\n",
    "        kwdf['keyword'] = kwdf['keyword'].apply(lambda word: eval(word))\n",
    "        \n",
    "        merged = kwdf.merge(paperdf, on = 'paperID')\n",
    "        \n",
    "        subgrp = merged.groupby(grouper)\n",
    "        \n",
    "        return merged, subgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPapersKWgroup(grouper):\n",
    "    with sqlite3.connect('Abstracts_DB.db') as con:\n",
    "        sqlcmd = \"SELECT paperID, title, confName, pubYear FROM PAPER \"\n",
    "        \n",
    "        paperdf = pd.read_sql_query(sqlcmd, con)\n",
    "        \n",
    "        sqlcmd2 = \"SELECT paperID, keyword FROM PAPERKEY \"\n",
    "        kwdf = pd.read_sql_query(sqlcmd2, con)\n",
    "        kwdf['keyword'] = kwdf['keyword'].apply(lambda word: eval(word))\n",
    "        \n",
    "        merged = kwdf.merge(paperdf, on = 'paperID')\n",
    "        \n",
    "        subgrp = merged.groupby(grouper)\n",
    "        \n",
    "        return merged, subgrp\n",
    "\n",
    "def getKWTrend(keyword):\n",
    "    paperFreq = getPapersKWgroup('keyword')\n",
    "    \n",
    "    #paperFreq['keyword'] = paperFreq['keyword'].apply(lambda word: eval(word))\n",
    "    \n",
    "    return paperFreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperKeyword = paperKey.groupby('paperID').count()\n",
    "paperKwYr = paperKey.groupby('pubYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperKwYr.get_group(2010)[['paperID', 'keyword']].groupby('keyword').count().sort('paperID', ascending = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enter a keyword and see trend over conference and year.\n",
    "try1 = paperKey\n",
    "try1 = try1.groupby('keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperFreq, merged = getPapersKWgroup('keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overallbreakdown = paperFreq.count()\n",
    "overallbreakdown.reset_index(inplace = True)\n",
    "overallbreakdown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib as plt\n",
    "%matplotlib inline\n",
    "def confYrKeywords(top = 10):\n",
    "    grouper = ['confName', 'pubYear']\n",
    "    m, f = getPapersKWgroup(grouper)\n",
    "    myentries = []\n",
    "    for group in f.groups.keys():\n",
    "        print group\n",
    "        keywordcts = f.get_group((group)).groupby([\"keyword\"])[\"keyword\"].count()\n",
    "        \n",
    "        kwdftop = keywordcts.sort_values(ascending = False).head(top)\n",
    "        \n",
    "        resetKW = pd.DataFrame(kwdftop).rename(columns = {'keyword' : 'count'})\n",
    "        entry = {}\n",
    "        entry['Group'] = group\n",
    "        \n",
    "        entry['Pie'] = getPieOne(resetKW, group)\n",
    "        entry['Counts'] = resetKW.to_html()\n",
    "        \n",
    "        myentries.append(entry)\n",
    "    \n",
    "    return dict(data = myentries)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "keywordcts = f.get_group(('ECSA', 2007)).groupby([\"keyword\"])[\"keyword\"].count()\n",
    "\n",
    "top10 = keywordcts.sort_values(ascending = False)\n",
    "top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "keywordcts.head(10).plot(kind = 'pie')\n",
    "getPieOne(keywordcts.head(10), ('ECSA', 2007) )\n",
    "kwdf = keywordcts.head(10)\n",
    "new = pd.DataFrame(kwdf).rename(columns = {'keyword' : 'count'})\n",
    "new\n",
    "getPieOne(new, ('ECSA', 2007))\n",
    "getBar(new, ('ECSA', 2007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tryit = confYrKeywords()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tryit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cStringIO import StringIO\n",
    "import base64\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def getPieOne(df, conference):\n",
    "    fig = plt.figure()\n",
    "    fig = df.plot(kind = 'pie', colormap = 'Blues', title = conference, subplots = True, legend = False, labels = ['' for x in np.arange(len(df))])\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    plt.legend( list(df.index),  bbox_to_anchor=(1.1, 1),\n",
    "              fontsize = \"xx-small\")\n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    return fig\n",
    "\n",
    "def getBar(df, conference):\n",
    "    \n",
    "    plt.figure()\n",
    "    ax =  df.plot(kind = 'bar', colormap = 'ocean', title = conference, subplots = True,legend = False)\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    \n",
    "def getBar2(df, conference, yaxis, xaxis, ylabel = 'count', xlabel = 'trada'):\n",
    "    plt.figure()\n",
    "    fig = sns.barplot(data = df, \n",
    "                      y = yaxis, \n",
    "                      x = xaxis, \n",
    "                      palette='Blues')\n",
    "    fig.set_ylabel(ylabel)\n",
    "    fig.set_xlabel(xlabel)\n",
    "    \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def getHeatMap(data_frame, indexCol = 'confName', cols = 'pubYear', vals = 'counts'):\n",
    "    plt.cla()\n",
    "    fig = sns.heatmap(data_frame.pivot_table(index=indexCol, \n",
    "                                             columns=cols, \n",
    "                                             values=vals),\n",
    "                                             cmap = 'Blues')\n",
    "    \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "def getLine(data_frame, xaxis = 'confName', yaxis = 'counts'):\n",
    "    plt.cla()\n",
    "    fig = sns.swarmplot(data = data_frame, x=xaxis, y = yaxis,palette = 'Blues')\n",
    "    \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getContentsconf():\n",
    "    with sqlite3.connect(mydb) as con:\n",
    "        sqlcmd = \"SELECT Conf, Year FROM ABSTRACTSTOTAL\"\n",
    "        df = pd.read_sql_query(sqlcmd, con)\n",
    "        myt = []\n",
    "    \n",
    "        \n",
    "        conferences = list(df['Conf'].unique())\n",
    "    \n",
    "   \n",
    "        for conf in conferences:\n",
    "        \n",
    "            entry = {}\n",
    "            entry['conf'] = conf\n",
    "        \n",
    "            subDF = df.query('Conf == \"%s\"' % conf).groupby('year').count()\n",
    "            entry['counts'] = subDF.to_html()\n",
    "            \n",
    "            image = getPieOne(subDF, conf)\n",
    "            entry['Pie']  = image\n",
    "            \n",
    "            subDF.reset_index(inplace = True)\n",
    "            image2 = getBar2(subDF, conf, xaxis = 'year', yaxis = 'Conf')\n",
    "            entry['Bar'] = image2\n",
    "        \n",
    "            myt.append(entry)\n",
    "    \n",
    "    return dict(data = myt), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g, d = getContentsconf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = getBar2(d, 'EC', xaxis = 'year', yaxis = 'Conf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "kwdf = keywordcts.sort_values(ascending = False)\n",
    "\n",
    "\n",
    "new = pd.DataFrame(kwdf.head(10)).rename(columns = {'keyword' : 'count'})\n",
    "f = getPieOne(new, ('ECSA', 2007) )\n",
    "new.reset_index(inplace = True)\n",
    "new\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = d.groupby(['Conf', 'year'])['Conf'].count().reset_index(name=\"counts\")\n",
    "sns.heatmap(df.pivot_table(index='year', columns='Conf', values='counts'),\n",
    "                                             cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.pivot_table(index='year', columns='Conf', values='counts'),\n",
    "                                             cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = []\n",
    "for idx in cts.index.get_values():\n",
    "    entry = {}\n",
    "    kw = cts.iloc[idx].keyword\n",
    "    entry['kw'] = cts.iloc[idx].keyword\n",
    "    entry['counts'] = cts.iloc[idx].counts\n",
    "    mygroup = f.get_group(kw)\n",
    "    entry['papers'] = list(mygroup.paperID)\n",
    "    entry['conferences'] = list(mygroup.confName)\n",
    "    entry['years'] = list(mygroup.pubYear)\n",
    "    table.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(table).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m= getPapersKWgroup2()\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getKWTRends(kw, grouper):\n",
    "    \n",
    "    m, f = getPapersKWgroup(grouper)\n",
    "    \n",
    "    query2 = '\"%s\" == keyword' %kw\n",
    "    \n",
    "    data_frame = m.copy()\n",
    "    data_frame.query(query2, inplace = True)\n",
    "    new = data_frame.copy()\n",
    "    \n",
    "    def findKWTrend(df, KWgrouper = [\"pubYear\", \"confName\"]):\n",
    "        labels = {'ECSA' : 0,\n",
    "                  'QoSA' : 1,\n",
    "                  'WICSA' : 2}\n",
    "        df = df.groupby(KWgrouper)['keyword'].count().reset_index(name=\"counts\")\n",
    "        df['confCode'] = df.confName.apply(lambda name: labels[name])\n",
    "        try:\n",
    "            return getHeatMap(df)\n",
    "        except:\n",
    "            return 'no data'\n",
    "        \n",
    "    \n",
    "    image = findKWTrend(new)\n",
    "    \n",
    "    myentry = [{'table' : data_frame.to_html(),\n",
    "              'trend'  : image\n",
    "               }]\n",
    "    \n",
    "    return dict(data = myentry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = getKWTRends('Research', 'keyword')\n",
    "t = getKWTRends('Research', 'keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = t.groupby([\"pubYear\", \"confName\"])['keyword'].count().reset_index(name=\"counts\")\n",
    "labels = {'ECSA' : 0,\n",
    "         'QoSA' : 1,\n",
    "         'WICSA' : 2}\n",
    "new['confCode'] = new.confName.apply(lambda name: labels[name])\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(new.pivot_table( index='confName', columns='pubYear', values='counts'), cmap = 'Blues')\n",
    "getHeatMap(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctsmerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPaperKW():\n",
    "    m, data_frame = getPapersKWgroup('paperID')\n",
    "    entries = []\n",
    "    for each in data_frame.groups:\n",
    "        entry = {}\n",
    "        entry['paperID'] = each\n",
    "        entry['keywords'] = [key for key in data_frame.get_group(each)['keyword']]\n",
    "        \n",
    "        entries.append(entry)\n",
    "    return dict(data = entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = getPaperKW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_kw(kw):\n",
    "    print \"kw\", kw\n",
    "    \n",
    "    \n",
    "    m, f = getPapersKWgroup('keyword')\n",
    "    cts = m.groupby([\"keyword\"])[\"keyword\"].count().reset_index(name=\"counts\")\n",
    "    ctsmerge = cts.merge(m, on = 'keyword').groupby('keyword')   \n",
    "    \n",
    "    try:\n",
    "        print kw\n",
    "        subgroup = ctsmerge.get_group(kw)\n",
    "        mytable = []\n",
    "            \n",
    "        for idx in subgroup.index.get_values():\n",
    "            print idx\n",
    "            entry = {}\n",
    "            entry['paperID'] = subgroup.loc[idx].paperID\n",
    "            entry['Title'] = subgroup.loc[idx]['title']\n",
    "            entry['Conference'] = subgroup.loc[idx]['confName']   \n",
    "            entry['PublicationYear'] = subgroup.loc[idx]['pubYear'] \n",
    "            mytable.append(entry)\n",
    "       \n",
    "        return dict(data = mytable)\n",
    "    except:\n",
    "        print (kw,'subgroupfail')\n",
    "        entry = {'paperID': 'No Keyword Found',\n",
    "                     'Title': 'No Keyword Found',\n",
    "                     'Conference': 'No Keyword Found',\n",
    "                     'PublicationYear': 'No Keyword Found'\n",
    "                     }\n",
    "        mytable = [entry]\n",
    "        return dict(data = mytable)\n",
    "\n",
    "\n",
    "kw =     'aspectual concept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kw2 = 'wireless sensor networks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_kw(u'vulnerability')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Affiliation_Paper Composite \n",
    "## necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "paperAffiliationDF = cmd.createAFFILIATIONPAPERTable(paperDF, affilDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>affilID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1482</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1483</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1484</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>1485</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1486</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paperID  affilID\n",
       "1481     1482     1107\n",
       "1482     1483      379\n",
       "1483     1484      379\n",
       "1484     1485      971\n",
       "1485     1486      412"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperAffiliationDF.tail()\n",
    "#paperAffiliationDF.to_csv('Tables_v1/paperAffiliation.csv', sheet_name = 'paperAffil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperDF[['paperID', 'pubYear']].merge(paperAffiliationDF, on = 'paperID').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPERAUTHORS COMPOSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB2.db database successfully\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "authorPaper = cmd.createPAPERAUTHORTable(paperDF[['paperID', 'authors']])\n",
    "#authorPaper.to_csv('Tables_v1/authorPaper.csv', sheet_name = 'paperAuthor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>authorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lopez Herrejon, Roberto E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Egyed, Alexander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Perovich, Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Rossel, Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Bastarrica, Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>a Cecilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Perovich, Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Rossel, Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Bastarrica, Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>a Cecilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Perovich, Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Rossel, Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Bastarrica, Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>a Cecilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>Hilliard, Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Malavolta, Ivano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Muccini, Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>Pelliccione, Patrizio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>Hilliard, Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>Malavolta, Ivano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paperID                 authorName\n",
       "0         1  Lopez Herrejon, Roberto E\n",
       "1         1           Egyed, Alexander\n",
       "2         2           Perovich, Daniel\n",
       "3         2            Rossel, Pedro O\n",
       "4         2            Bastarrica, Mar\n",
       "5         2                  a Cecilia\n",
       "6         3           Perovich, Daniel\n",
       "7         3            Rossel, Pedro O\n",
       "8         3            Bastarrica, Mar\n",
       "9         3                  a Cecilia\n",
       "10        4           Perovich, Daniel\n",
       "11        4            Rossel, Pedro O\n",
       "12        4            Bastarrica, Mar\n",
       "13        4                  a Cecilia\n",
       "14        5             Hilliard, Rich\n",
       "15        5           Malavolta, Ivano\n",
       "16        5             Muccini, Henry\n",
       "17        5      Pelliccione, Patrizio\n",
       "18        6             Hilliard, Rich\n",
       "19        6           Malavolta, Ivano"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorPaper.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperDF[['paperID', 'title']].merge(authorPaper, on = 'paperID').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confDF.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confDF.plot(kind = 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def createPAPERAUTHORdf(db = DEFAULTDB):\n",
    "    ''' Creating the PAPERAUTHOR COMPOSITE Table with \n",
    "    \n",
    "             : param data_frame : Pandas DataFrame from which to create the PAPER TABLE \n",
    "                 : - parsed paper table!\n",
    "             : param db : str. Name of db. (ie. 'Abstracts.db')\n",
    "                 : default 'test.db'\n",
    "             : param DFCol : tuple of strings Column names of data_frame with groupby cols.\n",
    "                 : default = [paperID','terms']\n",
    "                 : alternatively : enter with already unique table.\n",
    "             : param table : str. Name of Table to create or insert.\n",
    "                 : default : 'PAPERAUTHOR'\n",
    "             : param tableCols : tuple of str. Table keywords as tuple of strings\n",
    "                 : default  : ('paperID', 'authorName')\n",
    "             : param foreignKey : tuple of str. Foreign key names:\n",
    "                 : default : 'PAPER', 'AUTHORS'\n",
    "         \n",
    "             : output : Pandas DataFrame as output for inspection\n",
    "             : output : sql table created with rows inserted.\n",
    "         '''\n",
    "    def rech(names):\n",
    "        names2 = []\n",
    "        for a in names.split(\"'\"):\n",
    "            if a.strip() == \",\" :\n",
    "                pass\n",
    "            elif a.strip() == '':\n",
    "                pass\n",
    "            else:\n",
    "                names2.append(a)\n",
    "        return names2\n",
    "    \n",
    "    def createdf(df):\n",
    "        entries = []\n",
    "        \n",
    "        for each in df.index:\n",
    "            paperID = df.iloc[each].paperID\n",
    "            authors = df.iloc[each].NEWAUTHORS\n",
    "            index = np.array([paperID]*len(authors))\n",
    "            listau = zip(index, authors)\n",
    "    \n",
    "            entries.extend(listau)\n",
    "    \n",
    "        newdf = pd.DataFrame(entries)\n",
    "        newdf.rename(columns = {0:'paperID', 1:'authorName'}, inplace = True)\n",
    "        newdf.authorName = newdf.authorName.apply(lambda au: au.replace(\",\",' '))\n",
    "    \n",
    "        return newdf\n",
    "    \n",
    "    with sqlite3.connect(db) as con:\n",
    "        sqlcmd = \"SELECT * FROM AUTHORS\"\n",
    "        \n",
    "        audf = pd.read_sql_query(sqlcmd, con)\n",
    "        \n",
    "        sqlcmd2 = \"SELECT paperID, authors FROM PAPER\"\n",
    "        papdf = pd.read_sql_query(sqlcmd2, con)\n",
    "        \n",
    "        \n",
    "        \n",
    "        papdf['NEWAUTHORS'] = papdf[\"authors\"].apply(lambda a: a.strip(\"[]'\"))\n",
    "        papdf['NEWAUTHORS'] = papdf[\"NEWAUTHORS\"].apply(lambda a: rech(a))\n",
    "        \n",
    "        data_frame = createdf(papdf)\n",
    "        \n",
    "        return data_frame\n",
    "    \n",
    "def createPAPERAUTHORTable( db = DEFAULTDB, table = \"PAPERAUTHOR\"):\n",
    "    with sqlite3.connect(db) as con:\n",
    "        #create dataframe\n",
    "        df = createPAPERAUTHORdf()\n",
    "        \n",
    "        print df.head()\n",
    "        cur = con.cursor() \n",
    "        #drops the PaperAffilation table if it exist in db already\n",
    "        cur.execute(\"DROP TABLE IF EXISTS \" + table)\n",
    "        #and recreates it\n",
    "        cur.execute(\"CREATE TABLE \" + table + \"(\\\n",
    "            paperID INT, \\\n",
    "            authorName TEXT)\"\n",
    "                       );\n",
    "        \n",
    "        #insert into the table\n",
    "        df.to_sql(table, con, flavor='sqlite', \n",
    "                        schema=None, if_exists='append', \n",
    "                        index=False, index_label=None,\n",
    "                        chunksize=None, dtype=None)\n",
    "        print(\"Records created successfully\");\n",
    "        \n",
    "        sql = \"SELECT * FROM \" + table\n",
    "        testerDF = pd.read_sql_query(sql, con)\n",
    "        \n",
    "        return testerDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd = createPAPERAUTHORTable()\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPERAUTHOR TAKE 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   paperID                  authorName\n",
      "0        1   Lopez Herrejon  Roberto E\n",
      "1        1            Egyed  Alexander\n",
      "2        2            Perovich  Daniel\n",
      "3        2             Rossel  Pedro O\n",
      "4        2   Bastarrica  Mar a Cecilia\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "testerDF = authorPaper = cmd.createPAPERAUTHORTable2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>authorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lopez Herrejon  Roberto E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Egyed  Alexander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Perovich  Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Rossel  Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Bastarrica  Mar a Cecilia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paperID                  authorName\n",
       "0        1   Lopez Herrejon  Roberto E\n",
       "1        1            Egyed  Alexander\n",
       "2        2            Perovich  Daniel\n",
       "3        2             Rossel  Pedro O\n",
       "4        2   Bastarrica  Mar a Cecilia"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testerDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries:\n",
    "As for the given queries: \n",
    "papers with key word grouped by year.   \n",
    "- PaperID ---> KeywordFK, PaperID --> PublicationID:year\n",
    "\n",
    "author's most buzzy words : \n",
    "- authorID ---> paperID -->KeyWordId (count) (sort).max\n",
    "\n",
    "paper's affiliation grouped by conference and year  ??\n",
    "- paper ID:affiliation ---> publicationID:year -->ConferenceID:type\n",
    "\n",
    "conference/year and the keywords in order of frequency (ie word cloud visualization maybe?)  <<_--this might break it?\n",
    "- confID -->publicationID --> PaperIDs-->KeywordIDs (count) (sort descending)\n",
    "\n",
    "Affiliation's authors\n",
    "- authorsID--: papersIds: affiliation  (i need to check if an author can have multiple affiliations, I can't see why not if they change universities or companies after 10 years)\n",
    "\n",
    "\n",
    "Most frequent affiliations per conference\n",
    "paperIDs: affiliation --> publicationIDs --> ConferenceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = pk.merge(paperDF[['paperID', 'pubYear']], on = 'paperID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(q1['keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(authorPaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorAffiliation = authorPaper.merge(paperDF[['paperID', 'affiliation', 'pubYear']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorAffiliation.query('\"Muccini, Henry\" in authorName').sort('pubYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#paper's affiliation grouped by conference and year ??\n",
    "papafiil = paperAffiliationDF.merge(paperDF[['paperID', 'pubYear', 'confName']], on = 'paperID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groupPA = papafiil.groupby(['pubYear', 'confName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groupPA.aggregate('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
