{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now just using DF directly\n",
    "## no longer need to parse separately into lists etc.  all done internally\n",
    "## TO Do the dump load and initialize the DB, need to make sure correct order pf tables is loaded first those with no dependencies and then increasingly so.\n",
    "## now only erroring on original 3 .txt noted by Ian Gorton in original commnication\n",
    "- - 1. Conf\n",
    "- - 2. Pub , Keys, Authors, Affiliations (use sets to create unique ones but may change to all .unique)\n",
    "- - 3. Composites (Many to Many)\n",
    "- - 4. Paper/abstracts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 7)\n"
     ]
    }
   ],
   "source": [
    "import sqlcommands as cmd\n",
    "cmd = reload(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author affiliation</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Conf</th>\n",
       "      <th>Title</th>\n",
       "      <th>terms</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>The past 20 years has seen significant investm...</td>\n",
       "      <td>IBM Software Group, Raleigh, NC, United States...</td>\n",
       "      <td>['Brown, Alan W', '', '', ' McDermid, John A',...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>The art and science of software architecture</td>\n",
       "      <td>['Failure analysis', 'Systems engineering', 'O...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Nowadays, Wireless Sensor Networks  WSN  are a...</td>\n",
       "      <td>Divisi n de Sistemas e Ingenier a Electr nica ...</td>\n",
       "      <td>['Losilla, Fernando', '', '', 'Vicente Chicote...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Wireless sensor network application developmen...</td>\n",
       "      <td>['Mathematical models', 'Software architecture...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Automated services help enterprises create new...</td>\n",
       "      <td>INFOLAB, Tilburg University, Dept  of Informat...</td>\n",
       "      <td>['Papazoglou, Michael P', '', '']</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>What s in a service</td>\n",
       "      <td>['Condition monitoring', 'Electronic commerce'...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>The term co evolution describes the symbiotic ...</td>\n",
       "      <td>University of St Andrews, St Andrews, KY16 9SX...</td>\n",
       "      <td>['Morrison, Ron', '', '', 'Balasubramaniam, Dh...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>An active architecture approach to dynamic sys...</td>\n",
       "      <td>['Dynamical systems', 'Grid computing', 'Senso...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Software architecture views represent the basi...</td>\n",
       "      <td>Department of Information Systems and Computat...</td>\n",
       "      <td>['Cordero, Rogelio Limon', '', '', 'Salavert, ...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Analyzing styles of the modular software archi...</td>\n",
       "      <td>['Computer aided design', 'Requirements engine...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Currently, most software systems have a dynami...</td>\n",
       "      <td>Department of Information Systems and Computat...</td>\n",
       "      <td>['Costa, Crist bal', '', '', 'Ali, Nour', '', ...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Dynamic reconfiguration of software architectu...</td>\n",
       "      <td>['Computer aided design', 'Object oriented pro...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>We propose a pattern based software developmen...</td>\n",
       "      <td>Department of Computational and Cognitive Scie...</td>\n",
       "      <td>['C t , Isabelle', '', '', 'Heisel, Marina', '...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Pattern based evolution of software architectures</td>\n",
       "      <td>['Pattern recognition', 'Requirements engineer...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Most of the research in the area of multimodal...</td>\n",
       "      <td>Department of Computer Science, Technische Uni...</td>\n",
       "      <td>['Pereira, Alessandro Costa', ' ,', '', ' Hart...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>A distributed staged architecture for multimod...</td>\n",
       "      <td>['Computer programming languages', 'Distribute...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>The vast diversity of implementation and suppo...</td>\n",
       "      <td>Computer Languages and Systems II Department, ...</td>\n",
       "      <td>['L pez Sanz, Marcos', '', '', 'Acu a, C sar J...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>UML profile for the platform independent model...</td>\n",
       "      <td>['Computer simulation', 'Computer software por...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>No abstract available</td>\n",
       "      <td>None</td>\n",
       "      <td>['Dauvin, Jean Claude', ' Romana, Louis Alexan...</td>\n",
       "      <td>ECSA</td>\n",
       "      <td>Hydrobiologia  Preface</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Abstract  \\\n",
       "50  The past 20 years has seen significant investm...   \n",
       "51  Nowadays, Wireless Sensor Networks  WSN  are a...   \n",
       "52  Automated services help enterprises create new...   \n",
       "53  The term co evolution describes the symbiotic ...   \n",
       "54  Software architecture views represent the basi...   \n",
       "55  Currently, most software systems have a dynami...   \n",
       "56  We propose a pattern based software developmen...   \n",
       "57  Most of the research in the area of multimodal...   \n",
       "58  The vast diversity of implementation and suppo...   \n",
       "59                              No abstract available   \n",
       "\n",
       "                                   Author affiliation  \\\n",
       "50  IBM Software Group, Raleigh, NC, United States...   \n",
       "51  Divisi n de Sistemas e Ingenier a Electr nica ...   \n",
       "52  INFOLAB, Tilburg University, Dept  of Informat...   \n",
       "53  University of St Andrews, St Andrews, KY16 9SX...   \n",
       "54  Department of Information Systems and Computat...   \n",
       "55  Department of Information Systems and Computat...   \n",
       "56  Department of Computational and Cognitive Scie...   \n",
       "57  Department of Computer Science, Technische Uni...   \n",
       "58  Computer Languages and Systems II Department, ...   \n",
       "59                                               None   \n",
       "\n",
       "                                              Authors  Conf  \\\n",
       "50  ['Brown, Alan W', '', '', ' McDermid, John A',...  ECSA   \n",
       "51  ['Losilla, Fernando', '', '', 'Vicente Chicote...  ECSA   \n",
       "52                  ['Papazoglou, Michael P', '', '']  ECSA   \n",
       "53  ['Morrison, Ron', '', '', 'Balasubramaniam, Dh...  ECSA   \n",
       "54  ['Cordero, Rogelio Limon', '', '', 'Salavert, ...  ECSA   \n",
       "55  ['Costa, Crist bal', '', '', 'Ali, Nour', '', ...  ECSA   \n",
       "56  ['C t , Isabelle', '', '', 'Heisel, Marina', '...  ECSA   \n",
       "57  ['Pereira, Alessandro Costa', ' ,', '', ' Hart...  ECSA   \n",
       "58  ['L pez Sanz, Marcos', '', '', 'Acu a, C sar J...  ECSA   \n",
       "59  ['Dauvin, Jean Claude', ' Romana, Louis Alexan...  ECSA   \n",
       "\n",
       "                                                Title  \\\n",
       "50       The art and science of software architecture   \n",
       "51  Wireless sensor network application developmen...   \n",
       "52                                What s in a service   \n",
       "53  An active architecture approach to dynamic sys...   \n",
       "54  Analyzing styles of the modular software archi...   \n",
       "55  Dynamic reconfiguration of software architectu...   \n",
       "56  Pattern based evolution of software architectures   \n",
       "57  A distributed staged architecture for multimod...   \n",
       "58  UML profile for the platform independent model...   \n",
       "59                             Hydrobiologia  Preface   \n",
       "\n",
       "                                                terms  year  \n",
       "50  ['Failure analysis', 'Systems engineering', 'O...  2007  \n",
       "51  ['Mathematical models', 'Software architecture...  2007  \n",
       "52  ['Condition monitoring', 'Electronic commerce'...  2007  \n",
       "53  ['Dynamical systems', 'Grid computing', 'Senso...  2007  \n",
       "54  ['Computer aided design', 'Requirements engine...  2007  \n",
       "55  ['Computer aided design', 'Object oriented pro...  2007  \n",
       "56  ['Pattern recognition', 'Requirements engineer...  2007  \n",
       "57  ['Computer programming languages', 'Distribute...  2007  \n",
       "58  ['Computer simulation', 'Computer software por...  2007  \n",
       "59                                              [nan]  2007  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cmd.createTOTALTable()\n",
    "df.iloc[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#don't need \n",
    "#df1 = cmd.getPatentDataFrame(hdffile='../DataBaseParsing/DFstore4.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DISP, Univ  of Rome, Rome, Italy'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Author affiliation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Conf Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "confDF = cmd.createConfTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confID</th>\n",
       "      <th>confName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>QoSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WICSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confID confName\n",
       "0       1     ECSA\n",
       "1       2     QoSA\n",
       "2       3    WICSA"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create publications Table\n",
    "## Now can parse all the orginal .txt with exception of the same 3  Ian gorton noted were errant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "table dropped\n",
      "Created PUBLICATIONS table\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "pubDF = cmd.createPublicationsTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubID</th>\n",
       "      <th>year</th>\n",
       "      <th>confName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>ECSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pubID  year confName\n",
       "0      1  2007     ECSA\n",
       "1      2  2008     ECSA\n",
       "2      3  2009     ECSA\n",
       "3      4  2010     ECSA\n",
       "4      5  2011     ECSA"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubDF.head()\n",
    "#pubDF.to_csv('Tables_v1/publications.csv', sheet_name = 'publications')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Keys Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are errors here and I have spent way to ong trying to figure if out.  \n",
    "## Somewhere the abstracts are being split into the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "              keyword\n",
      "0     Loose couplings\n",
      "1   aspectual concept\n",
      "2       Discrete time\n",
      "3  Polyacrylonitriles\n",
      "4     Tacit knowledge\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "keys = cmd.createKEYSTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(keys)\n",
    "print len(keys.keyword.unique())\n",
    "keys.iloc[50:75]\n",
    "keys.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors\n",
    "## I don't know how to parse them better!  Each text file seems to look at them differently and no idea what to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Author set created\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "authorsDF = cmd.createAUTHORSTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2911\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorID</th>\n",
       "      <th>authorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kolb  Ronny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Von Massow  Robert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Smiley  Karen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prakash  Jai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Zhang  Hongye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorID          authorName\n",
       "0         1         Kolb  Ronny\n",
       "1         2  Von Massow  Robert\n",
       "2         3       Smiley  Karen\n",
       "3         4        Prakash  Jai\n",
       "4         5       Zhang  Hongye"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(authorsDF.authorName.drop_duplicates())  #<<--- double check!  will keep one 'empty ' ' becuase of set)\n",
    "authorsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEFAULTDB = mydb\n",
    "def createAUTHORSTable(data_frame, \n",
    "                    db = DEFAULTDB, \n",
    "                    DFCol = 'Authors',\n",
    "                    table = 'AUTHORS' ,\n",
    "                    tableCol = ['authorName']\n",
    "                   ):\n",
    "    ''' Creating the AUTHORS Table with \n",
    "            authorID as AUTOINCREMENTED PRIMARY KEY, \n",
    "             : param data_frame : Pandas DataFrame from which to create the AUTHORS TABLE\n",
    "             : param db : str. Name of db. (ie. 'Abstracts.db')\n",
    "                 : default 'test.db'\n",
    "             : param DFCol : tuple of strings Column names of data_frame with groupby cols.\n",
    "                 : default = 'Authors'\n",
    "                 : alternatively : enter with already unique table.\n",
    "             : param table : str. Name of Table to create or insert.\n",
    "                 : default : AUTHORS\n",
    "             : param tableCols : tuple of str. Table keywords as tuple of strings\n",
    "                 : default  : ('authorName')\n",
    "             : **NEED TO CREATE COMPOSITE **\n",
    "         \n",
    "             : output : Pandas DataFrame as output for inspection\n",
    "             : output : sql table created with rows inserted.\n",
    "         '''\n",
    "    \n",
    "    def findAuthorsSet(data_frame, DFCol = DFCol):\n",
    "        ''' Parse the TOTALABSTRACTS table dataframe terms column.\n",
    "        Create a single set of all terms\n",
    "        \n",
    "        : param data_frame : a Pandas DataFrame (ie TOTALABSTRACTS table as DF)\n",
    "        : param DFCol : column name to be recast and set of terms found from\n",
    "        \n",
    "        : output : a master set of terms set as a list (no duplicates)\n",
    "        '''\n",
    "        import re\n",
    "        commaQuote = re.compile('[\\',]')\n",
    "        \n",
    "    \n",
    "        #recast - since made a string during the entry into the sqlite db.\n",
    "        authors = data_frame[DFCol].apply(lambda a: a.strip(\"[]'\"))\n",
    "        authors = authors.apply(lambda x: filter(lambda a: a != '',\n",
    "                                                  commaQuote.sub(' ', x).split('   ')))\n",
    "        \n",
    "        \n",
    "        #create single set and remove leading white space\n",
    "        authors = list(frozenset().union(*authors))\n",
    "        authors = [anew.strip(' ') for anew in authors]\n",
    "        #need to reset becuase of the white space\n",
    "        return list(set(authors))\n",
    "    with sqlite3.connect(db) as con:\n",
    "        print (\"Opened %s database successfully\" %db); \n",
    "        cur = con.cursor() \n",
    "        #drops the Authors table if it exist in db already\n",
    "        cur.execute(\"DROP TABLE IF EXISTS \" + table)\n",
    "        #and recreates it\n",
    "        cur.execute(\"CREATE TABLE \" + table + \"(\\\n",
    "        authorID INTEGER PRIMARY KEY AUTOINCREMENT, \\\n",
    "        authorName TEXT \\\n",
    "        )\") \n",
    "        authors = findAuthorsSet(data_frame)\n",
    "        print ('Author set created')\n",
    "        \n",
    "        #only take 1 -> becuase first is empty\n",
    "        authorsDF = pd.DataFrame(authors[1:], columns = tableCol)\n",
    "        \n",
    "        #insert into the table\n",
    "        authorsDF.to_sql(table, con, flavor='sqlite', \n",
    "                    schema=None, if_exists='append', \n",
    "                    index=False, index_label=None,\n",
    "                    chunksize=None, dtype=None)\n",
    "        print(\"Records created successfully\");\n",
    "        \n",
    "    sql = \"SELECT * FROM \" + table\n",
    "    dfAuthors = pd.read_sql_query(sql, con)\n",
    "        \n",
    "    #return table as Pandas DataFrame for inspection\n",
    "    return dfAuthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Author set created\n",
      "Records created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorID</th>\n",
       "      <th>authorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kolb  Ronny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Von Massow  Robert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Smiley  Karen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prakash  Jai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Zhang  Hongye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorID          authorName\n",
       "0         1         Kolb  Ronny\n",
       "1         2  Von Massow  Robert\n",
       "2         3       Smiley  Karen\n",
       "3         4        Prakash  Jai\n",
       "4         5       Zhang  Hongye"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsDF = cmd.createAUTHORSTable(df)\n",
    "authorsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affiliation Table\n",
    "## simple no extra parsing do to differences between entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "affilDF= cmd.createAFFILIATIONTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affilID</th>\n",
       "      <th>affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DISP, Univ  of Rome, Rome, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LSTS   ENIT, Tunis, Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>INRIA, Univ  des Sci  et Technol  de Lille, Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sch  of Comput  Sci , Univ  of Adelaide, Adela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Software Group, IBM, Raleigh, NC, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   affilID                                        affiliation\n",
       "0        1                   DISP, Univ  of Rome, Rome, Italy\n",
       "1        2                        LSTS   ENIT, Tunis, Tunisia\n",
       "2        3  INRIA, Univ  des Sci  et Technol  de Lille, Vi...\n",
       "3        4  Sch  of Comput  Sci , Univ  of Adelaide, Adela...\n",
       "4        5    Software Group, IBM, Raleigh, NC, United States"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affilDF.head()\n",
    "#affilDF.to_csv('Tables_v1/affiliations.csv', sheet_name = 'affilations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PAPER TABLE\n",
    "## should this actually be made by first doing a join or something with the pub table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "table dropped\n",
      "Created PAPER table\n",
      "Created DataFrame\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "paperDF= cmd.createPAPERTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"['Software design', 'Structural properties', 'Feature models', 'Product-lines', 'Research challenges', 'Software product line architecture', 'Software product lines', 'Software systems', 'Structural Design', 'Computer Programming', 'Materials Science']\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperDF.iloc[0].terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydb = 'Abstracts_DB.db'\n",
    "#paperDF.to_csv('Tables_v1/paper.csv', sheet_name = 'paper')\n",
    "paperDFbyYrandConf = paperDF[['pubYear', 'confName', 'paperID']].groupby(['pubYear', 'confName'], axis = 0)\n",
    "#paperDFbyYrandConf.count().to_html()\n",
    "paperDFbyYrandConf.get_group((2007, 'ECSA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPapersConfYr(yr, conf):\n",
    "    with sqlite3.connect(mydb) as con:\n",
    "        sqlcmd = \"SELECT pubYear, confName, paperID, title, abstract FROM PAPER\"\n",
    "        PAPdf = pd.read_sql_query(sqlcmd, con)\n",
    "    \n",
    "        group = PAPdf.groupby(['pubYear', 'confName'], axis = 0)\n",
    "        subgrp = group.get_group((yr, conf))\n",
    "        \n",
    "        return subgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = getPapersConfYr(2004, 'WICSA')\n",
    "y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mytable = []\n",
    "for idx in y.index.get_values():\n",
    "    entry = {}\n",
    "    entry['paperID'] = y.loc[idx]['paperID']\n",
    "    entry['title'] = y.loc[idx]['title']\n",
    "    entry['abstract'] = y.loc[idx]['abstract']\n",
    "    mytable.append(entry)\n",
    "x = dict(data = mytable)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PAPERKEY COMPOSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sqlcommands.py:556: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  parsedPaper['NEWTERMS'] = parsedPaper[DFCol[-1]].apply(lambda x:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "pk = cmd.createPAPERKEYTable(paperDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Research challenges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Software product line architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Structural properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Software product lines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paperID                             keyword\n",
       "0        1                 Research challenges\n",
       "1        1  Software product line architecture\n",
       "2        1                   Materials Science\n",
       "3        1               Structural properties\n",
       "4        1              Software product lines"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperKey = pk.merge(paperDF[['paperID', 'title','confName', 'pubYear']], on = 'paperID')\n",
    "paperKey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPapersKWgroup(grouper):\n",
    "    with sqlite3.connect('Abstracts_DB.db') as con:\n",
    "        sqlcmd = \"SELECT paperID, title, confName, pubYear FROM PAPER \"\n",
    "        \n",
    "        paperdf = pd.read_sql_query(sqlcmd, con)\n",
    "        \n",
    "        sqlcmd2 = \"SELECT paperID, keyword FROM PAPERKEY \"\n",
    "        kwdf = pd.read_sql_query(sqlcmd2, con)\n",
    "        kwdf['keyword'] = kwdf['keyword'].apply(lambda word: eval(word))\n",
    "        \n",
    "        merged = kwdf.merge(paperdf, on = 'paperID')\n",
    "        \n",
    "        subgrp = merged.groupby(grouper)\n",
    "        \n",
    "        return merged, subgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPapersKWgroup(grouper):\n",
    "    with sqlite3.connect('Abstracts_DB.db') as con:\n",
    "        sqlcmd = \"SELECT paperID, title, confName, pubYear FROM PAPER \"\n",
    "        \n",
    "        paperdf = pd.read_sql_query(sqlcmd, con)\n",
    "        \n",
    "        sqlcmd2 = \"SELECT paperID, keyword FROM PAPERKEY \"\n",
    "        kwdf = pd.read_sql_query(sqlcmd2, con)\n",
    "        kwdf['keyword'] = kwdf['keyword'].apply(lambda word: eval(word))\n",
    "        \n",
    "        merged = kwdf.merge(paperdf, on = 'paperID')\n",
    "        \n",
    "        subgrp = merged.groupby(grouper)\n",
    "        \n",
    "        return merged, subgrp\n",
    "\n",
    "def getKWTrend(keyword):\n",
    "    paperFreq = getPapersKWgroup('keyword')\n",
    "    \n",
    "    #paperFreq['keyword'] = paperFreq['keyword'].apply(lambda word: eval(word))\n",
    "    \n",
    "    return paperFreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperKeyword = paperKey.groupby('paperID').count()\n",
    "paperKwYr = paperKey.groupby('pubYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperKwYr.get_group(2010)[['paperID', 'keyword']].groupby('keyword').count().sort('paperID', ascending = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enter a keyword and see trend over conference and year.\n",
    "try1 = paperKey\n",
    "try1 = try1.groupby('keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperFreq, merged = getPapersKWgroup('keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overallbreakdown = paperFreq.count()\n",
    "overallbreakdown.reset_index(inplace = True)\n",
    "overallbreakdown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib as plt\n",
    "%matplotlib inline\n",
    "def confYrKeywords(top = 10):\n",
    "    grouper = ['confName', 'pubYear']\n",
    "    m, f = getPapersKWgroup(grouper)\n",
    "    myentries = []\n",
    "    for group in f.groups.keys():\n",
    "        print group\n",
    "        keywordcts = f.get_group((group)).groupby([\"keyword\"])[\"keyword\"].count()\n",
    "        \n",
    "        kwdftop = keywordcts.sort_values(ascending = False).head(top)\n",
    "        \n",
    "        resetKW = pd.DataFrame(kwdftop).rename(columns = {'keyword' : 'count'})\n",
    "        entry = {}\n",
    "        entry['Group'] = group\n",
    "        \n",
    "        entry['Pie'] = getPieOne(resetKW, group)\n",
    "        entry['Counts'] = resetKW.to_html()\n",
    "        \n",
    "        myentries.append(entry)\n",
    "    \n",
    "    return dict(data = myentries)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "keywordcts = f.get_group(('ECSA', 2007)).groupby([\"keyword\"])[\"keyword\"].count()\n",
    "\n",
    "top10 = keywordcts.sort_values(ascending = False)\n",
    "top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "keywordcts.head(10).plot(kind = 'pie')\n",
    "getPieOne(keywordcts.head(10), ('ECSA', 2007) )\n",
    "kwdf = keywordcts.head(10)\n",
    "new = pd.DataFrame(kwdf).rename(columns = {'keyword' : 'count'})\n",
    "new\n",
    "getPieOne(new, ('ECSA', 2007))\n",
    "getBar(new, ('ECSA', 2007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tryit = confYrKeywords()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tryit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cStringIO import StringIO\n",
    "import base64\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def getPieOne(df, conference):\n",
    "    fig = plt.figure()\n",
    "    fig = df.plot(kind = 'pie', colormap = 'Blues', title = conference, subplots = True, legend = False, labels = ['' for x in np.arange(len(df))])\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    plt.legend( list(df.index),  bbox_to_anchor=(1.1, 1),\n",
    "              fontsize = \"xx-small\")\n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    return fig\n",
    "\n",
    "def getBar(df, conference):\n",
    "    \n",
    "    plt.figure()\n",
    "    ax =  df.plot(kind = 'bar', colormap = 'ocean', title = conference, subplots = True,legend = False)\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    \n",
    "def getBar2(df, conference, yaxis, xaxis, ylabel = 'count', xlabel = 'trada'):\n",
    "    plt.figure()\n",
    "    fig = sns.barplot(data = df, \n",
    "                      y = yaxis, \n",
    "                      x = xaxis, \n",
    "                      palette='Blues')\n",
    "    fig.set_ylabel(ylabel)\n",
    "    fig.set_xlabel(xlabel)\n",
    "    \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def getHeatMap(data_frame, indexCol = 'confName', cols = 'pubYear', vals = 'counts'):\n",
    "    plt.cla()\n",
    "    fig = sns.heatmap(data_frame.pivot_table(index=indexCol, \n",
    "                                             columns=cols, \n",
    "                                             values=vals),\n",
    "                                             cmap = 'Blues')\n",
    "    \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "def getLine(data_frame, xaxis = 'confName', yaxis = 'counts'):\n",
    "    plt.cla()\n",
    "    fig = sns.swarmplot(data = data_frame, x=xaxis, y = yaxis,palette = 'Blues')\n",
    "    \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    img = base64.encodestring(io.getvalue())\n",
    "   \n",
    "    io = StringIO()\n",
    "    plt.savefig(io, format='png')\n",
    "    data = base64.encodestring(io.getvalue())\n",
    "    script = '''<img src=\"data:image/png;base64,{}\";/>'''\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getContentsconf():\n",
    "    with sqlite3.connect(mydb) as con:\n",
    "        sqlcmd = \"SELECT Conf, Year FROM ABSTRACTSTOTAL\"\n",
    "        df = pd.read_sql_query(sqlcmd, con)\n",
    "        myt = []\n",
    "    \n",
    "        \n",
    "        conferences = list(df['Conf'].unique())\n",
    "    \n",
    "   \n",
    "        for conf in conferences:\n",
    "        \n",
    "            entry = {}\n",
    "            entry['conf'] = conf\n",
    "        \n",
    "            subDF = df.query('Conf == \"%s\"' % conf).groupby('year').count()\n",
    "            entry['counts'] = subDF.to_html()\n",
    "            \n",
    "            image = getPieOne(subDF, conf)\n",
    "            entry['Pie']  = image\n",
    "            \n",
    "            subDF.reset_index(inplace = True)\n",
    "            image2 = getBar2(subDF, conf, xaxis = 'year', yaxis = 'Conf')\n",
    "            entry['Bar'] = image2\n",
    "        \n",
    "            myt.append(entry)\n",
    "    \n",
    "    return dict(data = myt), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g, d = getContentsconf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = getBar2(d, 'EC', xaxis = 'year', yaxis = 'Conf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "kwdf = keywordcts.sort_values(ascending = False)\n",
    "\n",
    "\n",
    "new = pd.DataFrame(kwdf.head(10)).rename(columns = {'keyword' : 'count'})\n",
    "f = getPieOne(new, ('ECSA', 2007) )\n",
    "new.reset_index(inplace = True)\n",
    "new\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = d.groupby(['Conf', 'year'])['Conf'].count().reset_index(name=\"counts\")\n",
    "sns.heatmap(df.pivot_table(index='year', columns='Conf', values='counts'),\n",
    "                                             cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.pivot_table(index='year', columns='Conf', values='counts'),\n",
    "                                             cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = []\n",
    "for idx in cts.index.get_values():\n",
    "    entry = {}\n",
    "    kw = cts.iloc[idx].keyword\n",
    "    entry['kw'] = cts.iloc[idx].keyword\n",
    "    entry['counts'] = cts.iloc[idx].counts\n",
    "    mygroup = f.get_group(kw)\n",
    "    entry['papers'] = list(mygroup.paperID)\n",
    "    entry['conferences'] = list(mygroup.confName)\n",
    "    entry['years'] = list(mygroup.pubYear)\n",
    "    table.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(table).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m= getPapersKWgroup2()\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getKWTRends(kw, grouper):\n",
    "    \n",
    "    m, f = getPapersKWgroup(grouper)\n",
    "    \n",
    "    query2 = '\"%s\" == keyword' %kw\n",
    "    \n",
    "    data_frame = m.copy()\n",
    "    data_frame.query(query2, inplace = True)\n",
    "    new = data_frame.copy()\n",
    "    \n",
    "    def findKWTrend(df, KWgrouper = [\"pubYear\", \"confName\"]):\n",
    "        labels = {'ECSA' : 0,\n",
    "                  'QoSA' : 1,\n",
    "                  'WICSA' : 2}\n",
    "        df = df.groupby(KWgrouper)['keyword'].count().reset_index(name=\"counts\")\n",
    "        df['confCode'] = df.confName.apply(lambda name: labels[name])\n",
    "        try:\n",
    "            return getHeatMap(df)\n",
    "        except:\n",
    "            return 'no data'\n",
    "        \n",
    "    \n",
    "    image = findKWTrend(new)\n",
    "    \n",
    "    myentry = [{'table' : data_frame.to_html(),\n",
    "              'trend'  : image\n",
    "               }]\n",
    "    \n",
    "    return dict(data = myentry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = getKWTRends('Research', 'keyword')\n",
    "t = getKWTRends('Research', 'keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = t.groupby([\"pubYear\", \"confName\"])['keyword'].count().reset_index(name=\"counts\")\n",
    "labels = {'ECSA' : 0,\n",
    "         'QoSA' : 1,\n",
    "         'WICSA' : 2}\n",
    "new['confCode'] = new.confName.apply(lambda name: labels[name])\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(new.pivot_table( index='confName', columns='pubYear', values='counts'), cmap = 'Blues')\n",
    "getHeatMap(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctsmerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPaperKW():\n",
    "    m, data_frame = getPapersKWgroup('paperID')\n",
    "    entries = []\n",
    "    for each in data_frame.groups:\n",
    "        entry = {}\n",
    "        entry['paperID'] = each\n",
    "        entry['keywords'] = [key for key in data_frame.get_group(each)['keyword']]\n",
    "        \n",
    "        entries.append(entry)\n",
    "    return dict(data = entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = getPaperKW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_kw(kw):\n",
    "    print \"kw\", kw\n",
    "    \n",
    "    \n",
    "    m, f = getPapersKWgroup('keyword')\n",
    "    cts = m.groupby([\"keyword\"])[\"keyword\"].count().reset_index(name=\"counts\")\n",
    "    ctsmerge = cts.merge(m, on = 'keyword').groupby('keyword')   \n",
    "    \n",
    "    try:\n",
    "        print kw\n",
    "        subgroup = ctsmerge.get_group(kw)\n",
    "        mytable = []\n",
    "            \n",
    "        for idx in subgroup.index.get_values():\n",
    "            print idx\n",
    "            entry = {}\n",
    "            entry['paperID'] = subgroup.loc[idx].paperID\n",
    "            entry['Title'] = subgroup.loc[idx]['title']\n",
    "            entry['Conference'] = subgroup.loc[idx]['confName']   \n",
    "            entry['PublicationYear'] = subgroup.loc[idx]['pubYear'] \n",
    "            mytable.append(entry)\n",
    "       \n",
    "        return dict(data = mytable)\n",
    "    except:\n",
    "        print (kw,'subgroupfail')\n",
    "        entry = {'paperID': 'No Keyword Found',\n",
    "                     'Title': 'No Keyword Found',\n",
    "                     'Conference': 'No Keyword Found',\n",
    "                     'PublicationYear': 'No Keyword Found'\n",
    "                     }\n",
    "        mytable = [entry]\n",
    "        return dict(data = mytable)\n",
    "\n",
    "\n",
    "kw =     'aspectual concept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kw2 = 'wireless sensor networks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_kw(u'vulnerability')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Affiliation_Paper Composite \n",
    "## necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "paperAffiliationDF = cmd.createAFFILIATIONPAPERTable(paperDF, affilDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>affilID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1482</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1483</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1484</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>1485</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1486</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paperID  affilID\n",
       "1481     1482     1107\n",
       "1482     1483      379\n",
       "1483     1484      379\n",
       "1484     1485      971\n",
       "1485     1486      412"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperAffiliationDF.tail()\n",
    "#paperAffiliationDF.to_csv('Tables_v1/paperAffiliation.csv', sheet_name = 'paperAffil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperDF[['paperID', 'pubYear']].merge(paperAffiliationDF, on = 'paperID').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPERAUTHORS COMPOSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Abstracts_DB.db database successfully\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "authorPaper = cmd.createPAPERAUTHORTable(paperDF[['paperID', 'authors']])\n",
    "#authorPaper.to_csv('Tables_v1/authorPaper.csv', sheet_name = 'paperAuthor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>authorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lopez Herrejon, Roberto E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Egyed, Alexander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Perovich, Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Rossel, Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Bastarrica, Mar a Cecilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Perovich, Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Rossel, Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Bastarrica, Mar a Cecilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Perovich, Daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Rossel, Pedro O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Bastarrica, Mar a Cecilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Wang, Rongfang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Wang, Hui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Wei, Bangxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>Wang, Wei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Lei, Ziqiang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>Hilliard, Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>Malavolta, Ivano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>Muccini, Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>Pelliccione, Patrizio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paperID                  authorName\n",
       "0         1   Lopez Herrejon, Roberto E\n",
       "1         1            Egyed, Alexander\n",
       "2         2            Perovich, Daniel\n",
       "3         2             Rossel, Pedro O\n",
       "4         2   Bastarrica, Mar a Cecilia\n",
       "5         3            Perovich, Daniel\n",
       "6         3             Rossel, Pedro O\n",
       "7         3   Bastarrica, Mar a Cecilia\n",
       "8         4            Perovich, Daniel\n",
       "9         4             Rossel, Pedro O\n",
       "10        4   Bastarrica, Mar a Cecilia\n",
       "11        5              Wang, Rongfang\n",
       "12        5                   Wang, Hui\n",
       "13        5               Wei, Bangxing\n",
       "14        5                   Wang, Wei\n",
       "15        5                Lei, Ziqiang\n",
       "16        6              Hilliard, Rich\n",
       "17        6            Malavolta, Ivano\n",
       "18        6              Muccini, Henry\n",
       "19        6       Pelliccione, Patrizio"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorPaper.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paperDF[['paperID', 'title']].merge(authorPaper, on = 'paperID').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confDF.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confDF.plot(kind = 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def createPAPERAUTHORdf(db = DEFAULTDB):\n",
    "    ''' Creating the PAPERAUTHOR COMPOSITE Table with \n",
    "    \n",
    "             : param data_frame : Pandas DataFrame from which to create the PAPER TABLE \n",
    "                 : - parsed paper table!\n",
    "             : param db : str. Name of db. (ie. 'Abstracts.db')\n",
    "                 : default 'test.db'\n",
    "             : param DFCol : tuple of strings Column names of data_frame with groupby cols.\n",
    "                 : default = [paperID','terms']\n",
    "                 : alternatively : enter with already unique table.\n",
    "             : param table : str. Name of Table to create or insert.\n",
    "                 : default : 'PAPERAUTHOR'\n",
    "             : param tableCols : tuple of str. Table keywords as tuple of strings\n",
    "                 : default  : ('paperID', 'authorName')\n",
    "             : param foreignKey : tuple of str. Foreign key names:\n",
    "                 : default : 'PAPER', 'AUTHORS'\n",
    "         \n",
    "             : output : Pandas DataFrame as output for inspection\n",
    "             : output : sql table created with rows inserted.\n",
    "         '''\n",
    "    def rech(names):\n",
    "        names2 = []\n",
    "        for a in names.split(\"'\"):\n",
    "            if a.strip() == \",\" :\n",
    "                pass\n",
    "            elif a.strip() == '':\n",
    "                pass\n",
    "            else:\n",
    "                names2.append(a)\n",
    "        return names2\n",
    "    \n",
    "    def createdf(df):\n",
    "        entries = []\n",
    "        \n",
    "        for each in df.index:\n",
    "            paperID = df.iloc[each].paperID\n",
    "            authors = df.iloc[each].NEWAUTHORS\n",
    "            index = np.array([paperID]*len(authors))\n",
    "            listau = zip(index, authors)\n",
    "    \n",
    "            entries.extend(listau)\n",
    "    \n",
    "        newdf = pd.DataFrame(entries)\n",
    "        newdf.rename(columns = {0:'paperID', 1:'authorName'}, inplace = True)\n",
    "        newdf.authorName = newdf.authorName.apply(lambda au: au.replace(\",\",' '))\n",
    "    \n",
    "        return newdf\n",
    "    \n",
    "    with sqlite3.connect(db) as con:\n",
    "        sqlcmd = \"SELECT * FROM AUTHORS\"\n",
    "        \n",
    "        audf = pd.read_sql_query(sqlcmd, con)\n",
    "        \n",
    "        sqlcmd2 = \"SELECT paperID, authors FROM PAPER\"\n",
    "        papdf = pd.read_sql_query(sqlcmd2, con)\n",
    "        \n",
    "        \n",
    "        \n",
    "        papdf['NEWAUTHORS'] = papdf[\"authors\"].apply(lambda a: a.strip(\"[]'\"))\n",
    "        papdf['NEWAUTHORS'] = papdf[\"NEWAUTHORS\"].apply(lambda a: rech(a))\n",
    "        \n",
    "        data_frame = createdf(papdf)\n",
    "        \n",
    "        return data_frame\n",
    "    \n",
    "def createPAPERAUTHORTable( db = DEFAULTDB, table = \"PAPERAUTHOR\"):\n",
    "    with sqlite3.connect(db) as con:\n",
    "        #create dataframe\n",
    "        df = createPAPERAUTHORdf()\n",
    "        \n",
    "        print df.head()\n",
    "        cur = con.cursor() \n",
    "        #drops the PaperAffilation table if it exist in db already\n",
    "        cur.execute(\"DROP TABLE IF EXISTS \" + table)\n",
    "        #and recreates it\n",
    "        cur.execute(\"CREATE TABLE \" + table + \"(\\\n",
    "            paperID INT, \\\n",
    "            authorName TEXT)\"\n",
    "                       );\n",
    "        \n",
    "        #insert into the table\n",
    "        df.to_sql(table, con, flavor='sqlite', \n",
    "                        schema=None, if_exists='append', \n",
    "                        index=False, index_label=None,\n",
    "                        chunksize=None, dtype=None)\n",
    "        print(\"Records created successfully\");\n",
    "        \n",
    "        sql = \"SELECT * FROM \" + table\n",
    "        testerDF = pd.read_sql_query(sql, con)\n",
    "        \n",
    "        return testerDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd = createPAPERAUTHORTable()\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPERAUTHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testerDF.dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries:\n",
    "As for the given queries: \n",
    "papers with key word grouped by year.   \n",
    "- PaperID ---> KeywordFK, PaperID --> PublicationID:year\n",
    "\n",
    "author's most buzzy words : \n",
    "- authorID ---> paperID -->KeyWordId (count) (sort).max\n",
    "\n",
    "paper's affiliation grouped by conference and year  ??\n",
    "- paper ID:affiliation ---> publicationID:year -->ConferenceID:type\n",
    "\n",
    "conference/year and the keywords in order of frequency (ie word cloud visualization maybe?)  <<_--this might break it?\n",
    "- confID -->publicationID --> PaperIDs-->KeywordIDs (count) (sort descending)\n",
    "\n",
    "Affiliation's authors\n",
    "- authorsID--: papersIds: affiliation  (i need to check if an author can have multiple affiliations, I can't see why not if they change universities or companies after 10 years)\n",
    "\n",
    "\n",
    "Most frequent affiliations per conference\n",
    "paperIDs: affiliation --> publicationIDs --> ConferenceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = pk.merge(paperDF[['paperID', 'pubYear']], on = 'paperID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(q1['keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(authorPaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorAffiliation = authorPaper.merge(paperDF[['paperID', 'affiliation', 'pubYear']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorAffiliation.query('\"Muccini, Henry\" in authorName').sort('pubYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#paper's affiliation grouped by conference and year ??\n",
    "papafiil = paperAffiliationDF.merge(paperDF[['paperID', 'pubYear', 'confName']], on = 'paperID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groupPA = papafiil.groupby(['pubYear', 'confName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groupPA.aggregate('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
