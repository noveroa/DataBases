{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1 = '../ArchConfAbstracts/ECSA2007.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "non_decimal = re.compile('[^a-zA-Z]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a Single file\n",
    "- using all labels\n",
    "- note issues in the columns, not all entries are the same \n",
    "- - must change the structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import singleFile as parser1\n",
    "reload(parser1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdict = parser1.parseFile(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in testdict.iteritems():\n",
    "    if k == 0:\n",
    "        pass\n",
    "    elif k == 1:\n",
    "        print k\n",
    "        f = pd.DataFrame(v, columns = ['Labels','Values'])\n",
    "        f = f.set_index('Labels').T\n",
    "        columns = f.columns\n",
    "    elif k == 2:\n",
    "        g = pd.DataFrame(v, columns = ['Labels','Values'])\n",
    "        g = g.set_index('Labels').T\n",
    "print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in testdict.iteritems():\n",
    "    if k == 0:\n",
    "        pass\n",
    "    elif k == 1:\n",
    "        print k\n",
    "        f = pd.DataFrame(v, columns = ['Labels','Values'])\n",
    "        f = f.set_index('Labels').T\n",
    "        columns = f.columns\n",
    "    else:\n",
    "        try:\n",
    "            g = pd.DataFrame(v, columns = ['Labels','Values'])\n",
    "            g = g.set_index('Labels').T\n",
    "            f.append(g, ignore_index = True)\n",
    "        except:\n",
    "            print k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf = parser1.parseEntrytoDF(file1)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regXsuperscript = re.compile('/\\p{No}/gu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testme(filethis):\n",
    "    f = open(filethis, \"r\")\n",
    "    i = 1\n",
    "    abstracts = {}\n",
    "    entry = []\n",
    "    nonlabels = ['authors', 'copyright', 'UNKNOWN']\n",
    "    for line in f:\n",
    "        if line[0].isdigit():\n",
    "            abstracts[i-1] = entry\n",
    "            entry = []\n",
    "            entry.append((str(i), regXsuperscript.sub(' ', line).strip()))\n",
    "            i = i + 1\n",
    "        else:\n",
    "            try:\n",
    "                #non_decimal = re.compile('[\\W_]+')\n",
    "                label, text = line.split(':', 1)\n",
    "                text = regXsuperscript.sub(' ', text)\n",
    "                label = regXsuperscript.sub(' ', label)\n",
    "                entry.append((label.strip(), text.strip()))\n",
    "            except:\n",
    "                if line is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    text = regXsuperscript.sub(' ', line)\n",
    "                    label = 'reparse'\n",
    "                    entry.append((label, text.strip()))\n",
    "                    \n",
    "                \n",
    "    f.close()\n",
    "    return abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = testme(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### appending dataframes together, \n",
    "- Note the descrepanies - -> look into the issues (Decide to change the structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x  = testdf.append(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf['IPC Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import parseFiles as parser2\n",
    "parser2 = reload(parser2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retest2 = parser2.parseEntrytoDF(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Falessi, D', ' Kruchten, P', ' Cantone, G']\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retest2['Authors'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Jerad, C', ' Barkaoui, K', ' Grissa Touzi, A']\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retest2['Authors'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Jerad, C', ' Barkaoui, K', ' Grissa Touzi, A']\""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retest2.iloc[1]['Authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformatcode(classcodes):\n",
    "    try:\n",
    "        codes = [x.split(' ',1)[1] for x in classcodes.split('   ')]\n",
    "        return codes\n",
    "    except:\n",
    "        return classcodes\n",
    "        \n",
    "def reformatTerms(terms):\n",
    "    from itertools import chain\n",
    "    try:\n",
    "        terms = [entry.split(' - ') for entry in terms]\n",
    "        return list(chain(*terms))\n",
    "    except:\n",
    "        return 'ERROR' + str(terms)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retest['Classification Code'] = retest['Classification Code'].apply(reformatcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Software engineering techniques', 'Software management']\n",
      "nan\n",
      "['software architecture - software quality', 'empirical software engineering - software architecture - software economics - software quality']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print retest.iloc[0]['Classification Code']\n",
    "print retest.iloc[22]['Classification Code']\n",
    "print retest.iloc[0]['terms']\n",
    "print retest.iloc[22]['terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['software architecture', 'software quality', 'empirical software engineering', 'software architecture', 'software economics', 'software quality']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "retest['terms1'] = retest.terms.apply(reformatTerms)\n",
    "print retest.iloc[0]['terms1']\n",
    "print retest.iloc[22]['terms1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retest['newterm'] = retest['terms1'] + retest['Classification Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['software architecture', 'software quality', 'empirical software engineering', 'software architecture', 'software economics', 'software quality', 'Software engineering techniques', 'Software management']\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print retest.iloc[0]['newterm']\n",
    "print retest.iloc[22]['newterm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseTerms(tableDF, keyword = 'terms'):\n",
    "    ''' Parse the TOTALABSTRACTS table dataframe terms column.\n",
    "        Create a single set of all terms\n",
    "        \n",
    "        : param tableDF : a Pandas DataFrame (ie TOTALABSTRACTS table as DF)\n",
    "        : param keyword : column name to be recast and set of terms found from\n",
    "        \n",
    "        : output : a master set of terms set as a list (no duplicates)\n",
    "    '''\n",
    "    \n",
    "    df = tableDF\n",
    "    \n",
    "    #recast - since made a string during the entry into the sqlite db.\n",
    "    df[keyword] = df[keyword].apply(lambda kw : ','.join(kw.split('-')))\n",
    "    \n",
    "    #strip the str from prior manipulation\n",
    "    terms = df[keyword].apply(lambda x: set([ e.strip(' \\'') for e in x.strip('[]\\'').split(',')]))\n",
    "    \n",
    "    #create a single set\n",
    "    termSet = frozenset().union(*terms)\n",
    "    \n",
    "    #return as a list\n",
    "    return list(termSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = retest.iloc[0].terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['software architecture',\n",
       " 'software quality',\n",
       " 'empirical software engineering',\n",
       " 'software architecture',\n",
       " 'software economics',\n",
       " 'software quality']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [entry.split(' - ') for entry in row]\n",
    "from itertools import chain\n",
    "list(chain(*r))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of hdfstorage command line script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTotal = pd.read_hdf('DFstore3.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "successFiles = pd.read_hdf('DFstore3.h5', 'files')\n",
    "failedFiles = pd.read_hdf('DFstore3.h5', 'errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../ArchConfAbstracts/ECSA2007.txt ../ArchConfAbstracts/ECSA2008.txt ../ArchConfAbstracts/ECSA2009.txt ../ArchConfAbstracts/ECSA2010.txt ../ArchConfAbstracts/ECSA2011.txt ../ArchConfAbstracts/ECSA2012.txt ../ArchConfAbstracts/ECSA2013.txt ../ArchConfAbstracts/ECSA2014.txt ../ArchConfAbstracts/QoSA2005.txt ../ArchConfAbstracts/QoSA2006.txt ../ArchConfAbstracts/QoSA2007.txt ../ArchConfAbstracts/QoSA2009.txt ../ArchConfAbstracts/QoSA2010.txt ../ArchConfAbstracts/QoSA2011.txt ../ArchConfAbstracts/QoSA2012.txt ../ArchConfAbstracts/QoSA2013.txt ../ArchConfAbstracts/QoSA2014.txt ../ArchConfAbstracts/WICSA2004.txt ../ArchConfAbstracts/WICSA2005.txt ../ArchConfAbstracts/WICSA2008.txt ../ArchConfAbstracts/WICSA2009.txt ../ArchConfAbstracts/WICSA2011.txt ../ArchConfAbstracts/WICSA2012.txt ../ArchConfAbstracts/WICSA2014.txt \n",
      "\n",
      "../ArchConfAbstracts/QoSA2008.txt ../ArchConfAbstracts/WICSA1999.txt ../ArchConfAbstracts/WICSA2001.txt ../ArchConfAbstracts/WICSA2002.txt ../ArchConfAbstracts/WICSA2007.txt\n"
     ]
    }
   ],
   "source": [
    "for x in successFiles : print x,\n",
    "print '\\n'\n",
    "for y in failedFiles : print y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         ['Falessi, D', ' Kruchten, P', ' Cantone, G']\n",
       "2      ['Jerad, C', ' Barkaoui, K', ' Grissa Touzi, A']\n",
       "3     ['Waignier, G', ' Le Meur, A', 'F', ' Duchien,...\n",
       "4     ['Falkner, K', ' Balasubramaniam, D', ' Detmol...\n",
       "5                      ['Brown, A W', ' McDermid, J A']\n",
       "6     ['Navarro, E', ' Letelier, P', ' Jaen, J', ' R...\n",
       "7                                        ['Kjaer, K E']\n",
       "8            ['Santos, A', ' Almeida, F', ' Blanco, V']\n",
       "9     ['Sant Anna, C', ' Figueiredo, E', ' Garcia, A...\n",
       "10    ['Lopez Sanz, M', ' Acuna, C J', ' Cuesta, C E...\n",
       "11       ['Farenhorst, R', ' Lago, P', ' van Vliet, H']\n",
       "12    ['Losilla, F', ' Vicente Chicote, C', ' Alvare...\n",
       "13    ['Correia, R', ' Matos, C M P', ' Heckel, R', ...\n",
       "14                         ['Estevez, E', ' Marcos, M']\n",
       "15    ['Costa, C', ' Ali, N', ' Perez, J', ' Carsi, ...\n",
       "16                   ['Cordero, R L', ' Salavert, I R']\n",
       "17                          ['Gruhn, V', ' Schafer, C']\n",
       "18                                        ['Garlan, D']\n",
       "19    ['Martfnez Prieto, M A', ' Cuesta, C E', ' de ...\n",
       "20                    ['Harrison, N B', ' Avgeriou, P']\n",
       "21    ['Camara, J', ' Canal, C', ' Cube, J', ' Muril...\n",
       "22    ['Oquendo, Flavio', ' Cuesta, Carlos E', 'Marc...\n",
       "23    ['Manset, David', ' Verjus, Herve', ' McClatch...\n",
       "24    ['Sant Anna, Cl udio', ' ,', ' Figueiredo, Edu...\n",
       "25    ['Loulou, Imen', 'Kacem, Ahmed Hadj', 'Jmaiel,...\n",
       "26    ['C mara, Javier', 'Canal, Carlos', 'Cubo, Jav...\n",
       "27    ['Farenhorst, Rik', 'Lago, Patricia', 'Van Vli...\n",
       "28                           ['Zalewski, Andrzej', ' ']\n",
       "29    ['Waignier, Guillaume', 'Le Meur, Anne Fran oi...\n",
       "30    ['Ortiz, Francisco J', ' Pastor, Juan A', ' Al...\n",
       "                            ...                        \n",
       "32    ['Vierhauser, Michael', 'Rabiser, Rick', 'Grun...\n",
       "33       ['Babazadeh, Masiar', 'Pautasso, Cesare', ' ']\n",
       "34    ['Costa, Bruno', 'Pires, Paulo F', ' Delicato,...\n",
       "35    ['Tamburri, Damian A', ' Lago, Patricia', 'Dor...\n",
       "36    ['Galster, Matthias', 'Babar, Muhammad Ali', ' ']\n",
       "37    ['Baroni, Alessandro', 'Muccini, Henry', 'Mala...\n",
       "38      ['Chen, Lianping', 'Babar, Muhammad Ali', ' ,']\n",
       "39           ['Javed, Muhammad Atif', 'Zdun, Uwe', ' ']\n",
       "40    ['Manteuffel, Christian', 'Tofan, Dan', 'Kozio...\n",
       "41    ['Ali, Rima Al', 'Bures, Tomas', ' ,', ' Geros...\n",
       "42    ['Seele, Wilbert', 'Syed, Shaheen', 'Brinkkemp...\n",
       "43        ['Syromiatnikov, Artem', 'Weyns, Danny', ' ']\n",
       "44    ['Smiley, Karen', 'Mahate, Shakeel', 'Wood, Pa...\n",
       "45    ['Sapienza, Gaetana', 'Crnkovic, Ivica', 'Pote...\n",
       "46    ['Bianco, Vittorio Dal', 'Myllarniemi, Varvana...\n",
       "47    ['K rner, Marco', 'Herold, Sebastian', 'Rausch...\n",
       "48    ['Saadatmand, Mehrdad', ' ,', ' Scholle, Detle...\n",
       "49       ['Ahmad, Aakash', 'Babar, Muhammad Ali', ' ,']\n",
       "50    ['Mair, Matthias', 'Herold, Sebastian', 'Rausc...\n",
       "51    ['Dhungana, Deepak', 'Schreiner, Herwig', 'Leh...\n",
       "52           ['Pruijt, Leo', 'Brinkkemper, Sjaak', ' ']\n",
       "53                               ['Khomh, Foutse', ' ']\n",
       "54       ['Ahmad, Aakash', 'Babar, Muhammad Ali', ' ,']\n",
       "55    ['De Andrade, Hugo Sica', ' ,', ' Almeida, Edu...\n",
       "56                             ['Feitosa, Daniel', ' ']\n",
       "57        ['Fernandez, Eduardo B', ' Monge, Raul', ' ']\n",
       "58    ['Guessi, Milena', 'Oquendo, Flavio', 'Nakagaw...\n",
       "59    ['Stevanetic, Srdjan', 'Javed, Muhammad Atif',...\n",
       "60                    ['Chauhan, Muhammad Aufeef', ' ']\n",
       "61    ['Sehestedt, Stephan', 'Cheng, Chih Hong', 'Bo...\n",
       "Name: Authors, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTotal.Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drafts for hdfstorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import HDFStore\n",
    "store = HDFStore('store.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store = HDFStore('store.h5')\n",
    "store['df'] = dfnew\n",
    "store['files'] = s\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = pd.read_hdf('DFstore.h5', 'files')\n",
    "dfs = pd.read_hdf('DFstore.h5', 'df')\n",
    "e = pd.read_hdf('DFstore.h5', 'errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series.from_array(['hi', 'bye'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "dfs = []\n",
    "def printFileName(filename):\n",
    "    print filename\n",
    "\n",
    "def main():\n",
    "    args = sys.argv[1:]\n",
    "    dataDFstore = HDFStore('databaseDF.store')\n",
    "    \n",
    "    for filename in args:\n",
    "        files.append(FileName(filename))\n",
    "        dfs.append(parser.parseEntrytoDF(FileName(filename)))\n",
    "        \n",
    "    dfnew = pd.concat(dfs, axis = 0)\n",
    "    \n",
    "    dataDFstore['df'] = dfnew\n",
    "    \n",
    "    print files\n",
    "    dataDFstore['files'] = files\n",
    "    \n",
    "    dataDFstore.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "#Then from the console, yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
